{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETER SEARCH FOR BASE GAN AND TRAINING OF BASE GAN WITH SELECTED PARAMETER\n",
    "We start with importing necessary libraries such as PyTorch and torchvision. Then we define generator and discriminator classes and their architectures. We also define a function to load images and apply transformations. After that we are loading the image dataset with defined function and we are performing data transformations. Next step is initializing Wasserstein loss function and defining the class “GANEstimator” and convergence score method. Then we create an Optuna study with 4 trials. Optuna object trains GAN with various combinations of these hyperparameters and then selects the best combination. With this study, aim is to find best combination of hyperparameter by experimenting. Due to limited computational power only 4 different trial is conducted with 4 combinations. Based on the convergence scores trial 2 selected as the best trial with best convergence score obtained -1.6689766645431519. Then we store the parameters of best trial selected. These will be used for transfer learning. We create “GANEstimator” instance with best hyperparameters and traine GAN with best hyperparameters. In the end we collect losses for this training and we plot these losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import optuna\n",
    "from pytorch_fid.fid_score import calculate_fid_given_paths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, image_channels=3, image_size=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.image_channels = image_channels\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 256, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, image_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_channels=3, image_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.image_channels = image_channels\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 1, 4, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "class CustomStemCellDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = self.get_image_paths()\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        image_paths = []\n",
    "        for filename in os.listdir(self.root):\n",
    "            if filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "                image_paths.append(os.path.join(self.root, filename))\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "def wasserstein_loss(real_output, fake_output):\n",
    "    return -(torch.mean(real_output) - torch.mean(fake_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANEstimator(nn.Module):\n",
    "    def __init__(self, latent_dim, image_channels, image_size, learning_rate, data_root):\n",
    "        super(GANEstimator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.image_channels = image_channels\n",
    "        self.image_size = image_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.data_root = data_root\n",
    "        self.generator = Generator(latent_dim, image_channels, image_size)\n",
    "        self.discriminator = Discriminator(image_channels, image_size)\n",
    "        self.optimizer_G = optim.RMSprop(self.generator.parameters(), lr=learning_rate)\n",
    "        self.optimizer_D = optim.RMSprop(self.discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "    def fit(self, num_epochs, batch_size, n_critic, clip_value, evaluation_interval):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        dataset = CustomStemCellDataset(root=self.data_root, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            for i, real_images in enumerate(dataloader):\n",
    "                # Training the discriminator\n",
    "                for _ in range(n_critic):\n",
    "                    self.discriminator.zero_grad()\n",
    "                    z = torch.randn(real_images.shape[0], self.latent_dim, 1, 1)\n",
    "                    fake_images = self.generator(z).detach()\n",
    "                    real_output = self.discriminator(real_images)\n",
    "                    fake_output = self.discriminator(fake_images)\n",
    "                    d_loss = wasserstein_loss(real_output, fake_output)\n",
    "                    d_loss.backward()\n",
    "                    self.optimizer_D.step()\n",
    "                    for p in self.discriminator.parameters():\n",
    "                        p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "                # Training the generator\n",
    "                self.generator.zero_grad()\n",
    "                z = torch.randn(real_images.shape[0], self.latent_dim, 1, 1)\n",
    "                fake_images = self.generator(z)\n",
    "                fake_output = self.discriminator(fake_images)\n",
    "                g_loss = -torch.mean(fake_output)\n",
    "                g_loss.backward()\n",
    "                self.optimizer_G.step()\n",
    "\n",
    "                if (i + 1) % evaluation_interval == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}] - Iteration [{i+1}/{len(dataloader)}] - \"\n",
    "                          f\"Discriminator Loss: {d_loss.item():.4f} - Generator Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "        return d_losses, g_losses\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        state = {\n",
    "            'generator': self.generator.state_dict(),\n",
    "            'discriminator': self.discriminator.state_dict(),\n",
    "            'optimizer_G': self.optimizer_G.state_dict(),\n",
    "            'optimizer_D': self.optimizer_D.state_dict(),\n",
    "        }\n",
    "        torch.save(state, save_path)\n",
    "    def plot_losses(self, d_losses, g_losses):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(d_losses, label=\"Discriminator Loss\")\n",
    "        plt.plot(g_losses, label=\"Generator Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"GAN Training Losses\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-21 23:40:25,453] A new study created in memory with name: no-name-83742f34-464a-4a72-a11f-b634beb69063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]\n",
      "Epoch [1/1] - Iteration [100/226] - Discriminator Loss: -0.3198 - Generator Loss: 0.3199\n",
      "Epoch [1/1] - Iteration [200/226] - Discriminator Loss: -0.1541 - Generator Loss: -0.0143\n",
      "Epoch [1/60]\n",
      "Epoch [1/60] - Iteration [100/226] - Discriminator Loss: -0.2208 - Generator Loss: 0.2638\n",
      "Epoch [1/60] - Iteration [200/226] - Discriminator Loss: -0.2737 - Generator Loss: 0.2867\n",
      "Epoch [2/60]\n",
      "Epoch [2/60] - Iteration [100/226] - Discriminator Loss: -0.2106 - Generator Loss: 0.2488\n",
      "Epoch [2/60] - Iteration [200/226] - Discriminator Loss: -0.2584 - Generator Loss: 0.1744\n",
      "Epoch [3/60]\n",
      "Epoch [3/60] - Iteration [100/226] - Discriminator Loss: -0.1666 - Generator Loss: 0.2065\n",
      "Epoch [3/60] - Iteration [200/226] - Discriminator Loss: -0.2675 - Generator Loss: 0.1904\n",
      "Epoch [4/60]\n",
      "Epoch [4/60] - Iteration [100/226] - Discriminator Loss: -0.2272 - Generator Loss: 0.2051\n",
      "Epoch [4/60] - Iteration [200/226] - Discriminator Loss: -0.2063 - Generator Loss: 0.1869\n",
      "Epoch [5/60]\n",
      "Epoch [5/60] - Iteration [100/226] - Discriminator Loss: -0.2052 - Generator Loss: 0.2355\n",
      "Epoch [5/60] - Iteration [200/226] - Discriminator Loss: -0.2297 - Generator Loss: 0.1444\n",
      "Epoch [6/60]\n",
      "Epoch [6/60] - Iteration [100/226] - Discriminator Loss: -0.1812 - Generator Loss: 0.2776\n",
      "Epoch [6/60] - Iteration [200/226] - Discriminator Loss: -0.1663 - Generator Loss: 0.2588\n",
      "Epoch [7/60]\n",
      "Epoch [7/60] - Iteration [100/226] - Discriminator Loss: -0.2443 - Generator Loss: 0.1763\n",
      "Epoch [7/60] - Iteration [200/226] - Discriminator Loss: -0.1086 - Generator Loss: 0.1278\n",
      "Epoch [8/60]\n",
      "Epoch [8/60] - Iteration [100/226] - Discriminator Loss: -0.2543 - Generator Loss: 0.2217\n",
      "Epoch [8/60] - Iteration [200/226] - Discriminator Loss: -0.2565 - Generator Loss: 0.1743\n",
      "Epoch [9/60]\n",
      "Epoch [9/60] - Iteration [100/226] - Discriminator Loss: -0.0692 - Generator Loss: 0.2753\n",
      "Epoch [9/60] - Iteration [200/226] - Discriminator Loss: -0.2486 - Generator Loss: 0.2144\n",
      "Epoch [10/60]\n",
      "Epoch [10/60] - Iteration [100/226] - Discriminator Loss: -0.2598 - Generator Loss: 0.2469\n",
      "Epoch [10/60] - Iteration [200/226] - Discriminator Loss: -0.2430 - Generator Loss: 0.2026\n",
      "Epoch [11/60]\n",
      "Epoch [11/60] - Iteration [100/226] - Discriminator Loss: -0.1101 - Generator Loss: 0.2182\n",
      "Epoch [11/60] - Iteration [200/226] - Discriminator Loss: -0.1895 - Generator Loss: 0.2272\n",
      "Epoch [12/60]\n",
      "Epoch [12/60] - Iteration [100/226] - Discriminator Loss: -0.2414 - Generator Loss: 0.1550\n",
      "Epoch [12/60] - Iteration [200/226] - Discriminator Loss: -0.2220 - Generator Loss: 0.0879\n",
      "Epoch [13/60]\n",
      "Epoch [13/60] - Iteration [100/226] - Discriminator Loss: -0.1655 - Generator Loss: 0.2406\n",
      "Epoch [13/60] - Iteration [200/226] - Discriminator Loss: -0.1580 - Generator Loss: 0.2753\n",
      "Epoch [14/60]\n",
      "Epoch [14/60] - Iteration [100/226] - Discriminator Loss: -0.2349 - Generator Loss: 0.2626\n",
      "Epoch [14/60] - Iteration [200/226] - Discriminator Loss: -0.2111 - Generator Loss: 0.1932\n",
      "Epoch [15/60]\n",
      "Epoch [15/60] - Iteration [100/226] - Discriminator Loss: -0.1938 - Generator Loss: 0.2195\n",
      "Epoch [15/60] - Iteration [200/226] - Discriminator Loss: -0.2151 - Generator Loss: 0.2059\n",
      "Epoch [16/60]\n",
      "Epoch [16/60] - Iteration [100/226] - Discriminator Loss: -0.2601 - Generator Loss: 0.2168\n",
      "Epoch [16/60] - Iteration [200/226] - Discriminator Loss: -0.2202 - Generator Loss: 0.1976\n",
      "Epoch [17/60]\n",
      "Epoch [17/60] - Iteration [100/226] - Discriminator Loss: -0.2340 - Generator Loss: 0.2596\n",
      "Epoch [17/60] - Iteration [200/226] - Discriminator Loss: -0.1860 - Generator Loss: 0.2234\n",
      "Epoch [18/60]\n",
      "Epoch [18/60] - Iteration [100/226] - Discriminator Loss: -0.1947 - Generator Loss: 0.2579\n",
      "Epoch [18/60] - Iteration [200/226] - Discriminator Loss: -0.2224 - Generator Loss: 0.1293\n",
      "Epoch [19/60]\n",
      "Epoch [19/60] - Iteration [100/226] - Discriminator Loss: -0.1534 - Generator Loss: 0.2859\n",
      "Epoch [19/60] - Iteration [200/226] - Discriminator Loss: -0.1797 - Generator Loss: 0.2334\n",
      "Epoch [20/60]\n",
      "Epoch [20/60] - Iteration [100/226] - Discriminator Loss: -0.0733 - Generator Loss: 0.2718\n",
      "Epoch [20/60] - Iteration [200/226] - Discriminator Loss: -0.2824 - Generator Loss: 0.2144\n",
      "Epoch [21/60]\n",
      "Epoch [21/60] - Iteration [100/226] - Discriminator Loss: -0.2261 - Generator Loss: 0.2597\n",
      "Epoch [21/60] - Iteration [200/226] - Discriminator Loss: -0.2132 - Generator Loss: 0.2341\n",
      "Epoch [22/60]\n",
      "Epoch [22/60] - Iteration [100/226] - Discriminator Loss: -0.1932 - Generator Loss: 0.2333\n",
      "Epoch [22/60] - Iteration [200/226] - Discriminator Loss: -0.2286 - Generator Loss: 0.1963\n",
      "Epoch [23/60]\n",
      "Epoch [23/60] - Iteration [100/226] - Discriminator Loss: -0.1967 - Generator Loss: 0.2874\n",
      "Epoch [23/60] - Iteration [200/226] - Discriminator Loss: -0.2336 - Generator Loss: 0.2382\n",
      "Epoch [24/60]\n",
      "Epoch [24/60] - Iteration [100/226] - Discriminator Loss: -0.2468 - Generator Loss: 0.0586\n",
      "Epoch [24/60] - Iteration [200/226] - Discriminator Loss: -0.1859 - Generator Loss: 0.2731\n",
      "Epoch [25/60]\n",
      "Epoch [25/60] - Iteration [100/226] - Discriminator Loss: -0.2370 - Generator Loss: 0.2219\n",
      "Epoch [25/60] - Iteration [200/226] - Discriminator Loss: -0.2049 - Generator Loss: 0.2497\n",
      "Epoch [26/60]\n",
      "Epoch [26/60] - Iteration [100/226] - Discriminator Loss: -0.2167 - Generator Loss: 0.2468\n",
      "Epoch [26/60] - Iteration [200/226] - Discriminator Loss: -0.2416 - Generator Loss: 0.2526\n",
      "Epoch [27/60]\n",
      "Epoch [27/60] - Iteration [100/226] - Discriminator Loss: -0.2346 - Generator Loss: 0.1921\n",
      "Epoch [27/60] - Iteration [200/226] - Discriminator Loss: -0.2122 - Generator Loss: 0.1652\n",
      "Epoch [28/60]\n",
      "Epoch [28/60] - Iteration [100/226] - Discriminator Loss: -0.1882 - Generator Loss: 0.2325\n",
      "Epoch [28/60] - Iteration [200/226] - Discriminator Loss: -0.2043 - Generator Loss: 0.2160\n",
      "Epoch [29/60]\n",
      "Epoch [29/60] - Iteration [100/226] - Discriminator Loss: -0.2422 - Generator Loss: 0.2315\n",
      "Epoch [29/60] - Iteration [200/226] - Discriminator Loss: -0.2368 - Generator Loss: 0.2408\n",
      "Epoch [30/60]\n",
      "Epoch [30/60] - Iteration [100/226] - Discriminator Loss: -0.2345 - Generator Loss: 0.2447\n",
      "Epoch [30/60] - Iteration [200/226] - Discriminator Loss: -0.2408 - Generator Loss: 0.2858\n",
      "Epoch [31/60]\n",
      "Epoch [31/60] - Iteration [100/226] - Discriminator Loss: -0.0585 - Generator Loss: 0.1916\n",
      "Epoch [31/60] - Iteration [200/226] - Discriminator Loss: -0.2268 - Generator Loss: 0.2125\n",
      "Epoch [32/60]\n",
      "Epoch [32/60] - Iteration [100/226] - Discriminator Loss: -0.2528 - Generator Loss: 0.1616\n",
      "Epoch [32/60] - Iteration [200/226] - Discriminator Loss: -0.2240 - Generator Loss: 0.2657\n",
      "Epoch [33/60]\n",
      "Epoch [33/60] - Iteration [100/226] - Discriminator Loss: -0.1989 - Generator Loss: 0.2462\n",
      "Epoch [33/60] - Iteration [200/226] - Discriminator Loss: -0.1935 - Generator Loss: 0.2400\n",
      "Epoch [34/60]\n",
      "Epoch [34/60] - Iteration [100/226] - Discriminator Loss: -0.2308 - Generator Loss: 0.2173\n",
      "Epoch [34/60] - Iteration [200/226] - Discriminator Loss: -0.2087 - Generator Loss: 0.2116\n",
      "Epoch [35/60]\n",
      "Epoch [35/60] - Iteration [100/226] - Discriminator Loss: -0.1508 - Generator Loss: 0.2568\n",
      "Epoch [35/60] - Iteration [200/226] - Discriminator Loss: -0.2625 - Generator Loss: 0.1493\n",
      "Epoch [36/60]\n",
      "Epoch [36/60] - Iteration [100/226] - Discriminator Loss: -0.2060 - Generator Loss: 0.2714\n",
      "Epoch [36/60] - Iteration [200/226] - Discriminator Loss: -0.2294 - Generator Loss: 0.1294\n",
      "Epoch [37/60]\n",
      "Epoch [37/60] - Iteration [100/226] - Discriminator Loss: -0.2482 - Generator Loss: 0.2226\n",
      "Epoch [37/60] - Iteration [200/226] - Discriminator Loss: -0.2693 - Generator Loss: 0.1372\n",
      "Epoch [38/60]\n",
      "Epoch [38/60] - Iteration [100/226] - Discriminator Loss: -0.2569 - Generator Loss: 0.2294\n",
      "Epoch [38/60] - Iteration [200/226] - Discriminator Loss: -0.2378 - Generator Loss: 0.1115\n",
      "Epoch [39/60]\n",
      "Epoch [39/60] - Iteration [100/226] - Discriminator Loss: -0.2169 - Generator Loss: 0.1978\n",
      "Epoch [39/60] - Iteration [200/226] - Discriminator Loss: -0.1663 - Generator Loss: 0.2781\n",
      "Epoch [40/60]\n",
      "Epoch [40/60] - Iteration [100/226] - Discriminator Loss: -0.2385 - Generator Loss: 0.1362\n",
      "Epoch [40/60] - Iteration [200/226] - Discriminator Loss: -0.1460 - Generator Loss: 0.2645\n",
      "Epoch [41/60]\n",
      "Epoch [41/60] - Iteration [100/226] - Discriminator Loss: -0.2342 - Generator Loss: 0.1248\n",
      "Epoch [41/60] - Iteration [200/226] - Discriminator Loss: -0.2352 - Generator Loss: 0.1826\n",
      "Epoch [42/60]\n",
      "Epoch [42/60] - Iteration [100/226] - Discriminator Loss: -0.2216 - Generator Loss: 0.2728\n",
      "Epoch [42/60] - Iteration [200/226] - Discriminator Loss: -0.2516 - Generator Loss: 0.2766\n",
      "Epoch [43/60]\n",
      "Epoch [43/60] - Iteration [100/226] - Discriminator Loss: -0.2064 - Generator Loss: 0.1974\n",
      "Epoch [43/60] - Iteration [200/226] - Discriminator Loss: -0.1240 - Generator Loss: 0.2256\n",
      "Epoch [44/60]\n",
      "Epoch [44/60] - Iteration [100/226] - Discriminator Loss: -0.2092 - Generator Loss: 0.2514\n",
      "Epoch [44/60] - Iteration [200/226] - Discriminator Loss: -0.0691 - Generator Loss: 0.1947\n",
      "Epoch [45/60]\n",
      "Epoch [45/60] - Iteration [100/226] - Discriminator Loss: -0.2350 - Generator Loss: 0.1742\n",
      "Epoch [45/60] - Iteration [200/226] - Discriminator Loss: -0.1751 - Generator Loss: 0.2665\n",
      "Epoch [46/60]\n",
      "Epoch [46/60] - Iteration [100/226] - Discriminator Loss: -0.2345 - Generator Loss: 0.1425\n",
      "Epoch [46/60] - Iteration [200/226] - Discriminator Loss: -0.1932 - Generator Loss: 0.1899\n",
      "Epoch [47/60]\n",
      "Epoch [47/60] - Iteration [100/226] - Discriminator Loss: -0.1588 - Generator Loss: 0.2368\n",
      "Epoch [47/60] - Iteration [200/226] - Discriminator Loss: -0.2452 - Generator Loss: 0.1844\n",
      "Epoch [48/60]\n",
      "Epoch [48/60] - Iteration [100/226] - Discriminator Loss: -0.1543 - Generator Loss: 0.2061\n",
      "Epoch [48/60] - Iteration [200/226] - Discriminator Loss: -0.1939 - Generator Loss: 0.2674\n",
      "Epoch [49/60]\n",
      "Epoch [49/60] - Iteration [100/226] - Discriminator Loss: -0.2492 - Generator Loss: 0.2128\n",
      "Epoch [49/60] - Iteration [200/226] - Discriminator Loss: -0.2101 - Generator Loss: 0.1983\n",
      "Epoch [50/60]\n",
      "Epoch [50/60] - Iteration [100/226] - Discriminator Loss: -0.2104 - Generator Loss: 0.2486\n",
      "Epoch [50/60] - Iteration [200/226] - Discriminator Loss: -0.2029 - Generator Loss: 0.2419\n",
      "Epoch [51/60]\n",
      "Epoch [51/60] - Iteration [100/226] - Discriminator Loss: -0.2283 - Generator Loss: 0.1309\n",
      "Epoch [51/60] - Iteration [200/226] - Discriminator Loss: -0.1468 - Generator Loss: 0.2149\n",
      "Epoch [52/60]\n",
      "Epoch [52/60] - Iteration [100/226] - Discriminator Loss: -0.2472 - Generator Loss: 0.1770\n",
      "Epoch [52/60] - Iteration [200/226] - Discriminator Loss: -0.2568 - Generator Loss: 0.2445\n",
      "Epoch [53/60]\n",
      "Epoch [53/60] - Iteration [100/226] - Discriminator Loss: -0.2216 - Generator Loss: 0.2361\n",
      "Epoch [53/60] - Iteration [200/226] - Discriminator Loss: -0.2532 - Generator Loss: 0.1864\n",
      "Epoch [54/60]\n",
      "Epoch [54/60] - Iteration [100/226] - Discriminator Loss: -0.2154 - Generator Loss: 0.2851\n",
      "Epoch [54/60] - Iteration [200/226] - Discriminator Loss: -0.1813 - Generator Loss: 0.2128\n",
      "Epoch [55/60]\n",
      "Epoch [55/60] - Iteration [100/226] - Discriminator Loss: -0.2167 - Generator Loss: 0.2606\n",
      "Epoch [55/60] - Iteration [200/226] - Discriminator Loss: -0.0994 - Generator Loss: 0.2304\n",
      "Epoch [56/60]\n",
      "Epoch [56/60] - Iteration [100/226] - Discriminator Loss: -0.2167 - Generator Loss: 0.2303\n",
      "Epoch [56/60] - Iteration [200/226] - Discriminator Loss: -0.2675 - Generator Loss: 0.1933\n",
      "Epoch [57/60]\n",
      "Epoch [57/60] - Iteration [100/226] - Discriminator Loss: -0.2096 - Generator Loss: 0.2052\n",
      "Epoch [57/60] - Iteration [200/226] - Discriminator Loss: -0.1515 - Generator Loss: 0.2393\n",
      "Epoch [58/60]\n",
      "Epoch [58/60] - Iteration [100/226] - Discriminator Loss: -0.1499 - Generator Loss: 0.2583\n",
      "Epoch [58/60] - Iteration [200/226] - Discriminator Loss: -0.1792 - Generator Loss: 0.2809\n",
      "Epoch [59/60]\n",
      "Epoch [59/60] - Iteration [100/226] - Discriminator Loss: -0.1648 - Generator Loss: 0.2823\n",
      "Epoch [59/60] - Iteration [200/226] - Discriminator Loss: -0.0860 - Generator Loss: 0.0946\n",
      "Epoch [60/60]\n",
      "Epoch [60/60] - Iteration [100/226] - Discriminator Loss: -0.2100 - Generator Loss: 0.1958\n",
      "Epoch [60/60] - Iteration [200/226] - Discriminator Loss: -0.1891 - Generator Loss: 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-22 08:22:26,308] Trial 0 finished with value: -0.9151990488171577 and parameters: {'latent_dim': 63, 'learning_rate': 0.008514099098724385, 'num_epochs': 60, 'batch_size': 32}. Best is trial 0 with value: -0.9151990488171577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]\n",
      "Epoch [1/1] - Iteration [100/113] - Discriminator Loss: -0.2756 - Generator Loss: 0.3412\n",
      "Epoch [1/60]\n",
      "Epoch [1/60] - Iteration [100/113] - Discriminator Loss: -0.2775 - Generator Loss: 0.2916\n",
      "Epoch [2/60]\n",
      "Epoch [2/60] - Iteration [100/113] - Discriminator Loss: -0.2748 - Generator Loss: 0.3222\n",
      "Epoch [3/60]\n",
      "Epoch [3/60] - Iteration [100/113] - Discriminator Loss: -0.2745 - Generator Loss: 0.3325\n",
      "Epoch [4/60]\n",
      "Epoch [4/60] - Iteration [100/113] - Discriminator Loss: -0.2788 - Generator Loss: 0.3236\n",
      "Epoch [5/60]\n",
      "Epoch [5/60] - Iteration [100/113] - Discriminator Loss: -0.2674 - Generator Loss: 0.3229\n",
      "Epoch [6/60]\n",
      "Epoch [6/60] - Iteration [100/113] - Discriminator Loss: -0.2685 - Generator Loss: 0.3209\n",
      "Epoch [7/60]\n",
      "Epoch [7/60] - Iteration [100/113] - Discriminator Loss: -0.2686 - Generator Loss: 0.3061\n",
      "Epoch [8/60]\n",
      "Epoch [8/60] - Iteration [100/113] - Discriminator Loss: -0.2652 - Generator Loss: 0.3266\n",
      "Epoch [9/60]\n",
      "Epoch [9/60] - Iteration [100/113] - Discriminator Loss: -0.2696 - Generator Loss: 0.3257\n",
      "Epoch [10/60]\n",
      "Epoch [10/60] - Iteration [100/113] - Discriminator Loss: -0.2824 - Generator Loss: 0.3272\n",
      "Epoch [11/60]\n",
      "Epoch [11/60] - Iteration [100/113] - Discriminator Loss: -0.2598 - Generator Loss: 0.3048\n",
      "Epoch [12/60]\n",
      "Epoch [12/60] - Iteration [100/113] - Discriminator Loss: -0.2854 - Generator Loss: 0.3142\n",
      "Epoch [13/60]\n",
      "Epoch [13/60] - Iteration [100/113] - Discriminator Loss: -0.2820 - Generator Loss: 0.3152\n",
      "Epoch [14/60]\n",
      "Epoch [14/60] - Iteration [100/113] - Discriminator Loss: -0.2824 - Generator Loss: 0.3182\n",
      "Epoch [15/60]\n",
      "Epoch [15/60] - Iteration [100/113] - Discriminator Loss: -0.2696 - Generator Loss: 0.3079\n",
      "Epoch [16/60]\n",
      "Epoch [16/60] - Iteration [100/113] - Discriminator Loss: -0.2739 - Generator Loss: 0.3018\n",
      "Epoch [17/60]\n",
      "Epoch [17/60] - Iteration [100/113] - Discriminator Loss: -0.2593 - Generator Loss: 0.3077\n",
      "Epoch [18/60]\n",
      "Epoch [18/60] - Iteration [100/113] - Discriminator Loss: -0.2840 - Generator Loss: 0.3063\n",
      "Epoch [19/60]\n",
      "Epoch [19/60] - Iteration [100/113] - Discriminator Loss: -0.2812 - Generator Loss: 0.3030\n",
      "Epoch [20/60]\n",
      "Epoch [20/60] - Iteration [100/113] - Discriminator Loss: -0.2789 - Generator Loss: 0.2984\n",
      "Epoch [21/60]\n",
      "Epoch [21/60] - Iteration [100/113] - Discriminator Loss: -0.2687 - Generator Loss: 0.3217\n",
      "Epoch [22/60]\n",
      "Epoch [22/60] - Iteration [100/113] - Discriminator Loss: -0.2689 - Generator Loss: 0.3025\n",
      "Epoch [23/60]\n",
      "Epoch [23/60] - Iteration [100/113] - Discriminator Loss: -0.2826 - Generator Loss: 0.3018\n",
      "Epoch [24/60]\n",
      "Epoch [24/60] - Iteration [100/113] - Discriminator Loss: -0.2709 - Generator Loss: 0.2625\n",
      "Epoch [25/60]\n",
      "Epoch [25/60] - Iteration [100/113] - Discriminator Loss: -0.2758 - Generator Loss: 0.3112\n",
      "Epoch [26/60]\n",
      "Epoch [26/60] - Iteration [100/113] - Discriminator Loss: -0.2837 - Generator Loss: 0.3194\n",
      "Epoch [27/60]\n",
      "Epoch [27/60] - Iteration [100/113] - Discriminator Loss: -0.2710 - Generator Loss: 0.2730\n",
      "Epoch [28/60]\n",
      "Epoch [28/60] - Iteration [100/113] - Discriminator Loss: -0.2671 - Generator Loss: 0.3003\n",
      "Epoch [29/60]\n",
      "Epoch [29/60] - Iteration [100/113] - Discriminator Loss: -0.2788 - Generator Loss: 0.3125\n",
      "Epoch [30/60]\n",
      "Epoch [30/60] - Iteration [100/113] - Discriminator Loss: -0.2718 - Generator Loss: 0.3083\n",
      "Epoch [31/60]\n",
      "Epoch [31/60] - Iteration [100/113] - Discriminator Loss: -0.2497 - Generator Loss: 0.3140\n",
      "Epoch [32/60]\n",
      "Epoch [32/60] - Iteration [100/113] - Discriminator Loss: -0.2781 - Generator Loss: 0.3053\n",
      "Epoch [33/60]\n",
      "Epoch [33/60] - Iteration [100/113] - Discriminator Loss: -0.2737 - Generator Loss: 0.2904\n",
      "Epoch [34/60]\n",
      "Epoch [34/60] - Iteration [100/113] - Discriminator Loss: -0.2593 - Generator Loss: 0.3093\n",
      "Epoch [35/60]\n",
      "Epoch [35/60] - Iteration [100/113] - Discriminator Loss: -0.2714 - Generator Loss: 0.3095\n",
      "Epoch [36/60]\n",
      "Epoch [36/60] - Iteration [100/113] - Discriminator Loss: -0.2664 - Generator Loss: 0.2995\n",
      "Epoch [37/60]\n",
      "Epoch [37/60] - Iteration [100/113] - Discriminator Loss: -0.2770 - Generator Loss: 0.2906\n",
      "Epoch [38/60]\n",
      "Epoch [38/60] - Iteration [100/113] - Discriminator Loss: -0.2800 - Generator Loss: 0.2909\n",
      "Epoch [39/60]\n",
      "Epoch [39/60] - Iteration [100/113] - Discriminator Loss: -0.2847 - Generator Loss: 0.2839\n",
      "Epoch [40/60]\n",
      "Epoch [40/60] - Iteration [100/113] - Discriminator Loss: -0.2624 - Generator Loss: 0.3056\n",
      "Epoch [41/60]\n",
      "Epoch [41/60] - Iteration [100/113] - Discriminator Loss: -0.2728 - Generator Loss: 0.2834\n",
      "Epoch [42/60]\n",
      "Epoch [42/60] - Iteration [100/113] - Discriminator Loss: -0.2663 - Generator Loss: 0.3103\n",
      "Epoch [43/60]\n",
      "Epoch [43/60] - Iteration [100/113] - Discriminator Loss: -0.2747 - Generator Loss: 0.3119\n",
      "Epoch [44/60]\n",
      "Epoch [44/60] - Iteration [100/113] - Discriminator Loss: -0.2824 - Generator Loss: 0.3046\n",
      "Epoch [45/60]\n",
      "Epoch [45/60] - Iteration [100/113] - Discriminator Loss: -0.2675 - Generator Loss: 0.3118\n",
      "Epoch [46/60]\n",
      "Epoch [46/60] - Iteration [100/113] - Discriminator Loss: -0.2721 - Generator Loss: 0.2681\n",
      "Epoch [47/60]\n",
      "Epoch [47/60] - Iteration [100/113] - Discriminator Loss: -0.2823 - Generator Loss: 0.3014\n",
      "Epoch [48/60]\n",
      "Epoch [48/60] - Iteration [100/113] - Discriminator Loss: -0.2832 - Generator Loss: 0.2905\n",
      "Epoch [49/60]\n",
      "Epoch [49/60] - Iteration [100/113] - Discriminator Loss: -0.2706 - Generator Loss: 0.2356\n",
      "Epoch [50/60]\n",
      "Epoch [50/60] - Iteration [100/113] - Discriminator Loss: -0.2893 - Generator Loss: 0.3093\n",
      "Epoch [51/60]\n",
      "Epoch [51/60] - Iteration [100/113] - Discriminator Loss: -0.2793 - Generator Loss: 0.2984\n",
      "Epoch [52/60]\n",
      "Epoch [52/60] - Iteration [100/113] - Discriminator Loss: -0.2789 - Generator Loss: 0.2709\n",
      "Epoch [53/60]\n",
      "Epoch [53/60] - Iteration [100/113] - Discriminator Loss: -0.2728 - Generator Loss: 0.3100\n",
      "Epoch [54/60]\n",
      "Epoch [54/60] - Iteration [100/113] - Discriminator Loss: -0.2646 - Generator Loss: 0.3078\n",
      "Epoch [55/60]\n",
      "Epoch [55/60] - Iteration [100/113] - Discriminator Loss: -0.2745 - Generator Loss: 0.2919\n",
      "Epoch [56/60]\n",
      "Epoch [56/60] - Iteration [100/113] - Discriminator Loss: -0.2701 - Generator Loss: 0.3166\n",
      "Epoch [57/60]\n",
      "Epoch [57/60] - Iteration [100/113] - Discriminator Loss: -0.2739 - Generator Loss: 0.3079\n",
      "Epoch [58/60]\n",
      "Epoch [58/60] - Iteration [100/113] - Discriminator Loss: -0.2785 - Generator Loss: 0.2976\n",
      "Epoch [59/60]\n",
      "Epoch [59/60] - Iteration [100/113] - Discriminator Loss: -0.2772 - Generator Loss: 0.3038\n",
      "Epoch [60/60]\n",
      "Epoch [60/60] - Iteration [100/113] - Discriminator Loss: -0.2811 - Generator Loss: 0.2851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-22 14:13:41,440] Trial 1 finished with value: -1.6689766645431519 and parameters: {'latent_dim': 143, 'learning_rate': 0.0027601997252430545, 'num_epochs': 60, 'batch_size': 64}. Best is trial 1 with value: -1.6689766645431519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]\n",
      "Epoch [1/1] - Iteration [100/226] - Discriminator Loss: -0.3968 - Generator Loss: 0.3308\n",
      "Epoch [1/1] - Iteration [200/226] - Discriminator Loss: -0.3980 - Generator Loss: 0.3297\n",
      "Epoch [1/60]\n",
      "Epoch [1/60] - Iteration [100/226] - Discriminator Loss: -0.4353 - Generator Loss: 0.3395\n",
      "Epoch [1/60] - Iteration [200/226] - Discriminator Loss: -0.3927 - Generator Loss: 0.3334\n",
      "Epoch [2/60]\n",
      "Epoch [2/60] - Iteration [100/226] - Discriminator Loss: -0.3620 - Generator Loss: 0.3118\n",
      "Epoch [2/60] - Iteration [200/226] - Discriminator Loss: -0.3977 - Generator Loss: 0.3563\n",
      "Epoch [3/60]\n",
      "Epoch [3/60] - Iteration [100/226] - Discriminator Loss: -0.3989 - Generator Loss: 0.3425\n",
      "Epoch [3/60] - Iteration [200/226] - Discriminator Loss: -0.3954 - Generator Loss: 0.3304\n",
      "Epoch [4/60]\n",
      "Epoch [4/60] - Iteration [100/226] - Discriminator Loss: -0.3923 - Generator Loss: 0.3484\n",
      "Epoch [4/60] - Iteration [200/226] - Discriminator Loss: -0.3776 - Generator Loss: 0.3230\n",
      "Epoch [5/60]\n",
      "Epoch [5/60] - Iteration [100/226] - Discriminator Loss: -0.4086 - Generator Loss: 0.3494\n",
      "Epoch [5/60] - Iteration [200/226] - Discriminator Loss: -0.4255 - Generator Loss: 0.3352\n",
      "Epoch [6/60]\n",
      "Epoch [6/60] - Iteration [100/226] - Discriminator Loss: -0.4020 - Generator Loss: 0.3491\n",
      "Epoch [6/60] - Iteration [200/226] - Discriminator Loss: -0.4093 - Generator Loss: 0.3483\n",
      "Epoch [7/60]\n",
      "Epoch [7/60] - Iteration [100/226] - Discriminator Loss: -0.4062 - Generator Loss: 0.3366\n",
      "Epoch [7/60] - Iteration [200/226] - Discriminator Loss: -0.3953 - Generator Loss: 0.3308\n",
      "Epoch [8/60]\n",
      "Epoch [8/60] - Iteration [100/226] - Discriminator Loss: -0.3871 - Generator Loss: 0.3054\n",
      "Epoch [8/60] - Iteration [200/226] - Discriminator Loss: -0.3863 - Generator Loss: 0.3260\n",
      "Epoch [9/60]\n",
      "Epoch [9/60] - Iteration [100/226] - Discriminator Loss: -0.4116 - Generator Loss: 0.3350\n",
      "Epoch [9/60] - Iteration [200/226] - Discriminator Loss: -0.4078 - Generator Loss: 0.3408\n",
      "Epoch [10/60]\n",
      "Epoch [10/60] - Iteration [100/226] - Discriminator Loss: -0.4153 - Generator Loss: 0.3402\n",
      "Epoch [10/60] - Iteration [200/226] - Discriminator Loss: -0.3872 - Generator Loss: 0.3355\n",
      "Epoch [11/60]\n",
      "Epoch [11/60] - Iteration [100/226] - Discriminator Loss: -0.3891 - Generator Loss: 0.3170\n",
      "Epoch [11/60] - Iteration [200/226] - Discriminator Loss: -0.4143 - Generator Loss: 0.3330\n",
      "Epoch [12/60]\n",
      "Epoch [12/60] - Iteration [100/226] - Discriminator Loss: -0.4096 - Generator Loss: 0.3390\n",
      "Epoch [12/60] - Iteration [200/226] - Discriminator Loss: -0.3714 - Generator Loss: 0.3200\n",
      "Epoch [13/60]\n",
      "Epoch [13/60] - Iteration [100/226] - Discriminator Loss: -0.4088 - Generator Loss: 0.3316\n",
      "Epoch [13/60] - Iteration [200/226] - Discriminator Loss: -0.3973 - Generator Loss: 0.3502\n",
      "Epoch [14/60]\n",
      "Epoch [14/60] - Iteration [100/226] - Discriminator Loss: -0.4200 - Generator Loss: 0.3288\n",
      "Epoch [14/60] - Iteration [200/226] - Discriminator Loss: -0.4028 - Generator Loss: 0.3377\n",
      "Epoch [15/60]\n",
      "Epoch [15/60] - Iteration [100/226] - Discriminator Loss: -0.4055 - Generator Loss: 0.3294\n",
      "Epoch [15/60] - Iteration [200/226] - Discriminator Loss: -0.3904 - Generator Loss: 0.3132\n",
      "Epoch [16/60]\n",
      "Epoch [16/60] - Iteration [100/226] - Discriminator Loss: -0.4100 - Generator Loss: 0.3366\n",
      "Epoch [16/60] - Iteration [200/226] - Discriminator Loss: -0.3986 - Generator Loss: 0.3254\n",
      "Epoch [17/60]\n",
      "Epoch [17/60] - Iteration [100/226] - Discriminator Loss: -0.4066 - Generator Loss: 0.3533\n",
      "Epoch [17/60] - Iteration [200/226] - Discriminator Loss: -0.3986 - Generator Loss: 0.3291\n",
      "Epoch [18/60]\n",
      "Epoch [18/60] - Iteration [100/226] - Discriminator Loss: -0.3545 - Generator Loss: 0.3146\n",
      "Epoch [18/60] - Iteration [200/226] - Discriminator Loss: -0.4133 - Generator Loss: 0.3375\n",
      "Epoch [19/60]\n",
      "Epoch [19/60] - Iteration [100/226] - Discriminator Loss: -0.3826 - Generator Loss: 0.2964\n",
      "Epoch [19/60] - Iteration [200/226] - Discriminator Loss: -0.4116 - Generator Loss: 0.3357\n",
      "Epoch [20/60]\n",
      "Epoch [20/60] - Iteration [100/226] - Discriminator Loss: -0.3732 - Generator Loss: 0.3007\n",
      "Epoch [20/60] - Iteration [200/226] - Discriminator Loss: -0.4036 - Generator Loss: 0.3359\n",
      "Epoch [21/60]\n",
      "Epoch [21/60] - Iteration [100/226] - Discriminator Loss: -0.3715 - Generator Loss: 0.3148\n",
      "Epoch [21/60] - Iteration [200/226] - Discriminator Loss: -0.3813 - Generator Loss: 0.3443\n",
      "Epoch [22/60]\n",
      "Epoch [22/60] - Iteration [100/226] - Discriminator Loss: -0.4088 - Generator Loss: 0.3391\n",
      "Epoch [22/60] - Iteration [200/226] - Discriminator Loss: -0.3979 - Generator Loss: 0.3427\n",
      "Epoch [23/60]\n",
      "Epoch [23/60] - Iteration [100/226] - Discriminator Loss: -0.3975 - Generator Loss: 0.3408\n",
      "Epoch [23/60] - Iteration [200/226] - Discriminator Loss: -0.4072 - Generator Loss: 0.3367\n",
      "Epoch [24/60]\n",
      "Epoch [24/60] - Iteration [100/226] - Discriminator Loss: -0.3870 - Generator Loss: 0.3519\n",
      "Epoch [24/60] - Iteration [200/226] - Discriminator Loss: -0.4101 - Generator Loss: 0.3327\n",
      "Epoch [25/60]\n",
      "Epoch [25/60] - Iteration [100/226] - Discriminator Loss: -0.4135 - Generator Loss: 0.3478\n",
      "Epoch [25/60] - Iteration [200/226] - Discriminator Loss: -0.3904 - Generator Loss: 0.3368\n",
      "Epoch [26/60]\n",
      "Epoch [26/60] - Iteration [100/226] - Discriminator Loss: -0.4048 - Generator Loss: 0.3264\n",
      "Epoch [26/60] - Iteration [200/226] - Discriminator Loss: -0.4024 - Generator Loss: 0.3244\n",
      "Epoch [27/60]\n",
      "Epoch [27/60] - Iteration [100/226] - Discriminator Loss: -0.3795 - Generator Loss: 0.3285\n",
      "Epoch [27/60] - Iteration [200/226] - Discriminator Loss: -0.4136 - Generator Loss: 0.3386\n",
      "Epoch [28/60]\n",
      "Epoch [28/60] - Iteration [100/226] - Discriminator Loss: -0.4064 - Generator Loss: 0.3396\n",
      "Epoch [28/60] - Iteration [200/226] - Discriminator Loss: -0.3978 - Generator Loss: 0.3337\n",
      "Epoch [29/60]\n",
      "Epoch [29/60] - Iteration [100/226] - Discriminator Loss: -0.3953 - Generator Loss: 0.3389\n",
      "Epoch [29/60] - Iteration [200/226] - Discriminator Loss: -0.4116 - Generator Loss: 0.3341\n",
      "Epoch [30/60]\n",
      "Epoch [30/60] - Iteration [100/226] - Discriminator Loss: -0.3710 - Generator Loss: 0.3045\n",
      "Epoch [30/60] - Iteration [200/226] - Discriminator Loss: -0.3985 - Generator Loss: 0.3326\n",
      "Epoch [31/60]\n",
      "Epoch [31/60] - Iteration [100/226] - Discriminator Loss: -0.3978 - Generator Loss: 0.3345\n",
      "Epoch [31/60] - Iteration [200/226] - Discriminator Loss: -0.4100 - Generator Loss: 0.3325\n",
      "Epoch [32/60]\n",
      "Epoch [32/60] - Iteration [100/226] - Discriminator Loss: -0.4097 - Generator Loss: 0.3428\n",
      "Epoch [32/60] - Iteration [200/226] - Discriminator Loss: -0.3938 - Generator Loss: 0.3384\n",
      "Epoch [33/60]\n",
      "Epoch [33/60] - Iteration [100/226] - Discriminator Loss: -0.3978 - Generator Loss: 0.3475\n",
      "Epoch [33/60] - Iteration [200/226] - Discriminator Loss: -0.4038 - Generator Loss: 0.3534\n",
      "Epoch [34/60]\n",
      "Epoch [34/60] - Iteration [100/226] - Discriminator Loss: -0.4120 - Generator Loss: 0.3379\n",
      "Epoch [34/60] - Iteration [200/226] - Discriminator Loss: -0.4122 - Generator Loss: 0.3346\n",
      "Epoch [35/60]\n",
      "Epoch [35/60] - Iteration [100/226] - Discriminator Loss: -0.4058 - Generator Loss: 0.3447\n",
      "Epoch [35/60] - Iteration [200/226] - Discriminator Loss: -0.3980 - Generator Loss: 0.3246\n",
      "Epoch [36/60]\n",
      "Epoch [36/60] - Iteration [100/226] - Discriminator Loss: -0.4133 - Generator Loss: 0.3383\n",
      "Epoch [36/60] - Iteration [200/226] - Discriminator Loss: -0.3814 - Generator Loss: 0.3116\n",
      "Epoch [37/60]\n",
      "Epoch [37/60] - Iteration [100/226] - Discriminator Loss: -0.4062 - Generator Loss: 0.3490\n",
      "Epoch [37/60] - Iteration [200/226] - Discriminator Loss: -0.3919 - Generator Loss: 0.3299\n",
      "Epoch [38/60]\n",
      "Epoch [38/60] - Iteration [100/226] - Discriminator Loss: -0.3850 - Generator Loss: 0.3039\n",
      "Epoch [38/60] - Iteration [200/226] - Discriminator Loss: -0.4077 - Generator Loss: 0.3287\n",
      "Epoch [39/60]\n",
      "Epoch [39/60] - Iteration [100/226] - Discriminator Loss: -0.3911 - Generator Loss: 0.3333\n",
      "Epoch [39/60] - Iteration [200/226] - Discriminator Loss: -0.3833 - Generator Loss: 0.3096\n",
      "Epoch [40/60]\n",
      "Epoch [40/60] - Iteration [100/226] - Discriminator Loss: -0.4113 - Generator Loss: 0.3350\n",
      "Epoch [40/60] - Iteration [200/226] - Discriminator Loss: -0.3505 - Generator Loss: 0.3236\n",
      "Epoch [41/60]\n",
      "Epoch [41/60] - Iteration [100/226] - Discriminator Loss: -0.3746 - Generator Loss: 0.3484\n",
      "Epoch [41/60] - Iteration [200/226] - Discriminator Loss: -0.4037 - Generator Loss: 0.3447\n",
      "Epoch [42/60]\n",
      "Epoch [42/60] - Iteration [100/226] - Discriminator Loss: -0.4014 - Generator Loss: 0.3400\n",
      "Epoch [42/60] - Iteration [200/226] - Discriminator Loss: -0.4115 - Generator Loss: 0.3434\n",
      "Epoch [43/60]\n",
      "Epoch [43/60] - Iteration [100/226] - Discriminator Loss: -0.4140 - Generator Loss: 0.3415\n",
      "Epoch [43/60] - Iteration [200/226] - Discriminator Loss: -0.3570 - Generator Loss: 0.3260\n",
      "Epoch [44/60]\n",
      "Epoch [44/60] - Iteration [100/226] - Discriminator Loss: -0.4116 - Generator Loss: 0.3370\n",
      "Epoch [44/60] - Iteration [200/226] - Discriminator Loss: -0.3799 - Generator Loss: 0.3238\n",
      "Epoch [45/60]\n",
      "Epoch [45/60] - Iteration [100/226] - Discriminator Loss: -0.3984 - Generator Loss: 0.3328\n",
      "Epoch [45/60] - Iteration [200/226] - Discriminator Loss: -0.3626 - Generator Loss: 0.3345\n",
      "Epoch [46/60]\n",
      "Epoch [46/60] - Iteration [100/226] - Discriminator Loss: -0.4002 - Generator Loss: 0.3386\n",
      "Epoch [46/60] - Iteration [200/226] - Discriminator Loss: -0.4083 - Generator Loss: 0.3432\n",
      "Epoch [47/60]\n",
      "Epoch [47/60] - Iteration [100/226] - Discriminator Loss: -0.3914 - Generator Loss: 0.3345\n",
      "Epoch [47/60] - Iteration [200/226] - Discriminator Loss: -0.4068 - Generator Loss: 0.3375\n",
      "Epoch [48/60]\n",
      "Epoch [48/60] - Iteration [100/226] - Discriminator Loss: -0.3656 - Generator Loss: 0.3113\n",
      "Epoch [48/60] - Iteration [200/226] - Discriminator Loss: -0.3978 - Generator Loss: 0.3415\n",
      "Epoch [49/60]\n",
      "Epoch [49/60] - Iteration [100/226] - Discriminator Loss: -0.4109 - Generator Loss: 0.3358\n",
      "Epoch [49/60] - Iteration [200/226] - Discriminator Loss: -0.3705 - Generator Loss: 0.3543\n",
      "Epoch [50/60]\n",
      "Epoch [50/60] - Iteration [100/226] - Discriminator Loss: -0.4084 - Generator Loss: 0.3358\n",
      "Epoch [50/60] - Iteration [200/226] - Discriminator Loss: -0.3962 - Generator Loss: 0.3339\n",
      "Epoch [51/60]\n",
      "Epoch [51/60] - Iteration [100/226] - Discriminator Loss: -0.4010 - Generator Loss: 0.3403\n",
      "Epoch [51/60] - Iteration [200/226] - Discriminator Loss: -0.4084 - Generator Loss: 0.3427\n",
      "Epoch [52/60]\n",
      "Epoch [52/60] - Iteration [100/226] - Discriminator Loss: -0.4089 - Generator Loss: 0.3299\n",
      "Epoch [52/60] - Iteration [200/226] - Discriminator Loss: -0.4083 - Generator Loss: 0.3118\n",
      "Epoch [53/60]\n",
      "Epoch [53/60] - Iteration [100/226] - Discriminator Loss: -0.4020 - Generator Loss: 0.3309\n",
      "Epoch [53/60] - Iteration [200/226] - Discriminator Loss: -0.3681 - Generator Loss: 0.2434\n",
      "Epoch [54/60]\n",
      "Epoch [54/60] - Iteration [100/226] - Discriminator Loss: -0.4070 - Generator Loss: 0.3399\n",
      "Epoch [54/60] - Iteration [200/226] - Discriminator Loss: -0.4075 - Generator Loss: 0.3389\n",
      "Epoch [55/60]\n",
      "Epoch [55/60] - Iteration [100/226] - Discriminator Loss: -0.3626 - Generator Loss: 0.2709\n",
      "Epoch [55/60] - Iteration [200/226] - Discriminator Loss: -0.3575 - Generator Loss: 0.3282\n",
      "Epoch [56/60]\n",
      "Epoch [56/60] - Iteration [100/226] - Discriminator Loss: -0.4096 - Generator Loss: 0.3371\n",
      "Epoch [56/60] - Iteration [200/226] - Discriminator Loss: -0.4104 - Generator Loss: 0.3372\n",
      "Epoch [57/60]\n",
      "Epoch [57/60] - Iteration [100/226] - Discriminator Loss: -0.3886 - Generator Loss: 0.3378\n",
      "Epoch [57/60] - Iteration [200/226] - Discriminator Loss: -0.3966 - Generator Loss: 0.3299\n",
      "Epoch [58/60]\n",
      "Epoch [58/60] - Iteration [100/226] - Discriminator Loss: -0.4103 - Generator Loss: 0.3488\n",
      "Epoch [58/60] - Iteration [200/226] - Discriminator Loss: -0.3747 - Generator Loss: 0.2997\n",
      "Epoch [59/60]\n",
      "Epoch [59/60] - Iteration [100/226] - Discriminator Loss: -0.3920 - Generator Loss: 0.3394\n",
      "Epoch [59/60] - Iteration [200/226] - Discriminator Loss: -0.4046 - Generator Loss: 0.3283\n",
      "Epoch [60/60]\n",
      "Epoch [60/60] - Iteration [100/226] - Discriminator Loss: -0.4125 - Generator Loss: 0.3356\n",
      "Epoch [60/60] - Iteration [200/226] - Discriminator Loss: -0.4030 - Generator Loss: 0.3435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-22 20:11:48,180] Trial 2 finished with value: 3.361900717020035 and parameters: {'latent_dim': 72, 'learning_rate': 0.000717965270738687, 'num_epochs': 60, 'batch_size': 32}. Best is trial 1 with value: -1.6689766645431519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]\n",
      "Epoch [1/1] - Iteration [100/226] - Discriminator Loss: -0.3858 - Generator Loss: 0.3160\n",
      "Epoch [1/1] - Iteration [200/226] - Discriminator Loss: -0.3910 - Generator Loss: 0.3361\n",
      "Epoch [1/50]\n",
      "Epoch [1/50] - Iteration [100/226] - Discriminator Loss: -0.4153 - Generator Loss: 0.3336\n",
      "Epoch [1/50] - Iteration [200/226] - Discriminator Loss: -0.3759 - Generator Loss: 0.3293\n",
      "Epoch [2/50]\n",
      "Epoch [2/50] - Iteration [100/226] - Discriminator Loss: -0.4253 - Generator Loss: 0.3356\n",
      "Epoch [2/50] - Iteration [200/226] - Discriminator Loss: -0.4253 - Generator Loss: 0.3351\n",
      "Epoch [3/50]\n",
      "Epoch [3/50] - Iteration [100/226] - Discriminator Loss: -0.4367 - Generator Loss: 0.3317\n",
      "Epoch [3/50] - Iteration [200/226] - Discriminator Loss: -0.4243 - Generator Loss: 0.3320\n",
      "Epoch [4/50]\n",
      "Epoch [4/50] - Iteration [100/226] - Discriminator Loss: -0.4259 - Generator Loss: 0.3353\n",
      "Epoch [4/50] - Iteration [200/226] - Discriminator Loss: -0.4253 - Generator Loss: 0.3331\n",
      "Epoch [5/50]\n",
      "Epoch [5/50] - Iteration [100/226] - Discriminator Loss: -0.4216 - Generator Loss: 0.3309\n",
      "Epoch [5/50] - Iteration [200/226] - Discriminator Loss: -0.3972 - Generator Loss: 0.3128\n",
      "Epoch [6/50]\n",
      "Epoch [6/50] - Iteration [100/226] - Discriminator Loss: -0.4275 - Generator Loss: 0.3357\n",
      "Epoch [6/50] - Iteration [200/226] - Discriminator Loss: -0.4251 - Generator Loss: 0.3309\n",
      "Epoch [7/50]\n",
      "Epoch [7/50] - Iteration [100/226] - Discriminator Loss: -0.4257 - Generator Loss: 0.3362\n",
      "Epoch [7/50] - Iteration [200/226] - Discriminator Loss: -0.4245 - Generator Loss: 0.3337\n",
      "Epoch [8/50]\n",
      "Epoch [8/50] - Iteration [100/226] - Discriminator Loss: -0.4261 - Generator Loss: 0.3350\n",
      "Epoch [8/50] - Iteration [200/226] - Discriminator Loss: -0.4088 - Generator Loss: 0.3412\n",
      "Epoch [9/50]\n",
      "Epoch [9/50] - Iteration [100/226] - Discriminator Loss: -0.4314 - Generator Loss: 0.3380\n",
      "Epoch [9/50] - Iteration [200/226] - Discriminator Loss: -0.4209 - Generator Loss: 0.3398\n",
      "Epoch [10/50]\n",
      "Epoch [10/50] - Iteration [100/226] - Discriminator Loss: -0.4360 - Generator Loss: 0.3291\n",
      "Epoch [10/50] - Iteration [200/226] - Discriminator Loss: -0.4273 - Generator Loss: 0.3354\n",
      "Epoch [11/50]\n",
      "Epoch [11/50] - Iteration [100/226] - Discriminator Loss: -0.4523 - Generator Loss: 0.3373\n",
      "Epoch [11/50] - Iteration [200/226] - Discriminator Loss: -0.4241 - Generator Loss: 0.3329\n",
      "Epoch [12/50]\n",
      "Epoch [12/50] - Iteration [100/226] - Discriminator Loss: -0.4261 - Generator Loss: 0.3326\n",
      "Epoch [12/50] - Iteration [200/226] - Discriminator Loss: -0.4247 - Generator Loss: 0.3364\n",
      "Epoch [13/50]\n",
      "Epoch [13/50] - Iteration [100/226] - Discriminator Loss: -0.4059 - Generator Loss: 0.3369\n",
      "Epoch [13/50] - Iteration [200/226] - Discriminator Loss: -0.4327 - Generator Loss: 0.3358\n",
      "Epoch [14/50]\n",
      "Epoch [14/50] - Iteration [100/226] - Discriminator Loss: -0.4170 - Generator Loss: 0.3345\n",
      "Epoch [14/50] - Iteration [200/226] - Discriminator Loss: -0.4265 - Generator Loss: 0.3332\n",
      "Epoch [15/50]\n",
      "Epoch [15/50] - Iteration [100/226] - Discriminator Loss: -0.4298 - Generator Loss: 0.3371\n",
      "Epoch [15/50] - Iteration [200/226] - Discriminator Loss: -0.4283 - Generator Loss: 0.3340\n",
      "Epoch [16/50]\n",
      "Epoch [16/50] - Iteration [100/226] - Discriminator Loss: -0.4297 - Generator Loss: 0.3317\n",
      "Epoch [16/50] - Iteration [200/226] - Discriminator Loss: -0.4281 - Generator Loss: 0.3361\n",
      "Epoch [17/50]\n",
      "Epoch [17/50] - Iteration [100/226] - Discriminator Loss: -0.4270 - Generator Loss: 0.3360\n",
      "Epoch [17/50] - Iteration [200/226] - Discriminator Loss: -0.4213 - Generator Loss: 0.3315\n",
      "Epoch [18/50]\n",
      "Epoch [18/50] - Iteration [100/226] - Discriminator Loss: -0.4298 - Generator Loss: 0.3326\n",
      "Epoch [18/50] - Iteration [200/226] - Discriminator Loss: -0.4213 - Generator Loss: 0.3325\n",
      "Epoch [19/50]\n",
      "Epoch [19/50] - Iteration [100/226] - Discriminator Loss: -0.4286 - Generator Loss: 0.3346\n",
      "Epoch [19/50] - Iteration [200/226] - Discriminator Loss: -0.4314 - Generator Loss: 0.3346\n",
      "Epoch [20/50]\n",
      "Epoch [20/50] - Iteration [100/226] - Discriminator Loss: -0.4335 - Generator Loss: 0.3348\n",
      "Epoch [20/50] - Iteration [200/226] - Discriminator Loss: -0.4300 - Generator Loss: 0.3370\n",
      "Epoch [21/50]\n",
      "Epoch [21/50] - Iteration [100/226] - Discriminator Loss: -0.4002 - Generator Loss: 0.3401\n",
      "Epoch [21/50] - Iteration [200/226] - Discriminator Loss: -0.4308 - Generator Loss: 0.3334\n",
      "Epoch [22/50]\n",
      "Epoch [22/50] - Iteration [100/226] - Discriminator Loss: -0.4271 - Generator Loss: 0.3355\n",
      "Epoch [22/50] - Iteration [200/226] - Discriminator Loss: -0.4256 - Generator Loss: 0.3334\n",
      "Epoch [23/50]\n",
      "Epoch [23/50] - Iteration [100/226] - Discriminator Loss: -0.4302 - Generator Loss: 0.3334\n",
      "Epoch [23/50] - Iteration [200/226] - Discriminator Loss: -0.4127 - Generator Loss: 0.3121\n",
      "Epoch [24/50]\n",
      "Epoch [24/50] - Iteration [100/226] - Discriminator Loss: -0.4259 - Generator Loss: 0.3344\n",
      "Epoch [24/50] - Iteration [200/226] - Discriminator Loss: -0.4249 - Generator Loss: 0.3269\n",
      "Epoch [25/50]\n",
      "Epoch [25/50] - Iteration [100/226] - Discriminator Loss: -0.4274 - Generator Loss: 0.3351\n",
      "Epoch [25/50] - Iteration [200/226] - Discriminator Loss: -0.4339 - Generator Loss: 0.3341\n",
      "Epoch [26/50]\n",
      "Epoch [26/50] - Iteration [100/226] - Discriminator Loss: -0.4292 - Generator Loss: 0.3296\n",
      "Epoch [26/50] - Iteration [200/226] - Discriminator Loss: -0.4284 - Generator Loss: 0.3326\n",
      "Epoch [27/50]\n",
      "Epoch [27/50] - Iteration [100/226] - Discriminator Loss: -0.4285 - Generator Loss: 0.3366\n",
      "Epoch [27/50] - Iteration [200/226] - Discriminator Loss: -0.4299 - Generator Loss: 0.3341\n",
      "Epoch [28/50]\n",
      "Epoch [28/50] - Iteration [100/226] - Discriminator Loss: -0.4279 - Generator Loss: 0.3365\n",
      "Epoch [28/50] - Iteration [200/226] - Discriminator Loss: -0.4082 - Generator Loss: 0.3343\n",
      "Epoch [29/50]\n",
      "Epoch [29/50] - Iteration [100/226] - Discriminator Loss: -0.4249 - Generator Loss: 0.3313\n",
      "Epoch [29/50] - Iteration [200/226] - Discriminator Loss: -0.4236 - Generator Loss: 0.3317\n",
      "Epoch [30/50]\n",
      "Epoch [30/50] - Iteration [100/226] - Discriminator Loss: -0.4309 - Generator Loss: 0.3331\n",
      "Epoch [30/50] - Iteration [200/226] - Discriminator Loss: -0.4329 - Generator Loss: 0.3377\n",
      "Epoch [31/50]\n",
      "Epoch [31/50] - Iteration [100/226] - Discriminator Loss: -0.4188 - Generator Loss: 0.3247\n",
      "Epoch [31/50] - Iteration [200/226] - Discriminator Loss: -0.4285 - Generator Loss: 0.3352\n",
      "Epoch [32/50]\n",
      "Epoch [32/50] - Iteration [100/226] - Discriminator Loss: -0.4246 - Generator Loss: 0.3332\n",
      "Epoch [32/50] - Iteration [200/226] - Discriminator Loss: -0.4257 - Generator Loss: 0.3347\n",
      "Epoch [33/50]\n",
      "Epoch [33/50] - Iteration [100/226] - Discriminator Loss: -0.4260 - Generator Loss: 0.3364\n",
      "Epoch [33/50] - Iteration [200/226] - Discriminator Loss: -0.4131 - Generator Loss: 0.3196\n",
      "Epoch [34/50]\n",
      "Epoch [34/50] - Iteration [100/226] - Discriminator Loss: -0.4324 - Generator Loss: 0.3354\n",
      "Epoch [34/50] - Iteration [200/226] - Discriminator Loss: -0.4323 - Generator Loss: 0.3327\n",
      "Epoch [35/50]\n",
      "Epoch [35/50] - Iteration [100/226] - Discriminator Loss: -0.4289 - Generator Loss: 0.3348\n",
      "Epoch [35/50] - Iteration [200/226] - Discriminator Loss: -0.4203 - Generator Loss: 0.3331\n",
      "Epoch [36/50]\n",
      "Epoch [36/50] - Iteration [100/226] - Discriminator Loss: -0.4188 - Generator Loss: 0.3353\n",
      "Epoch [36/50] - Iteration [200/226] - Discriminator Loss: -0.4076 - Generator Loss: 0.3407\n",
      "Epoch [37/50]\n",
      "Epoch [37/50] - Iteration [100/226] - Discriminator Loss: -0.4252 - Generator Loss: 0.3334\n",
      "Epoch [37/50] - Iteration [200/226] - Discriminator Loss: -0.4317 - Generator Loss: 0.3370\n",
      "Epoch [38/50]\n",
      "Epoch [38/50] - Iteration [100/226] - Discriminator Loss: -0.4267 - Generator Loss: 0.3355\n",
      "Epoch [38/50] - Iteration [200/226] - Discriminator Loss: -0.4297 - Generator Loss: 0.3332\n",
      "Epoch [39/50]\n",
      "Epoch [39/50] - Iteration [100/226] - Discriminator Loss: -0.4315 - Generator Loss: 0.3365\n",
      "Epoch [39/50] - Iteration [200/226] - Discriminator Loss: -0.4322 - Generator Loss: 0.3381\n",
      "Epoch [40/50]\n",
      "Epoch [40/50] - Iteration [100/226] - Discriminator Loss: -0.4293 - Generator Loss: 0.3346\n",
      "Epoch [40/50] - Iteration [200/226] - Discriminator Loss: -0.4266 - Generator Loss: 0.3355\n",
      "Epoch [41/50]\n",
      "Epoch [41/50] - Iteration [100/226] - Discriminator Loss: -0.4274 - Generator Loss: 0.3333\n",
      "Epoch [41/50] - Iteration [200/226] - Discriminator Loss: -0.4253 - Generator Loss: 0.3330\n",
      "Epoch [42/50]\n",
      "Epoch [42/50] - Iteration [100/226] - Discriminator Loss: -0.4299 - Generator Loss: 0.3330\n",
      "Epoch [42/50] - Iteration [200/226] - Discriminator Loss: -0.4302 - Generator Loss: 0.3311\n",
      "Epoch [43/50]\n",
      "Epoch [43/50] - Iteration [100/226] - Discriminator Loss: -0.4304 - Generator Loss: 0.3357\n",
      "Epoch [43/50] - Iteration [200/226] - Discriminator Loss: -0.4285 - Generator Loss: 0.3360\n",
      "Epoch [44/50]\n",
      "Epoch [44/50] - Iteration [100/226] - Discriminator Loss: -0.4285 - Generator Loss: 0.3343\n",
      "Epoch [44/50] - Iteration [200/226] - Discriminator Loss: -0.4265 - Generator Loss: 0.3339\n",
      "Epoch [45/50]\n",
      "Epoch [45/50] - Iteration [100/226] - Discriminator Loss: -0.4240 - Generator Loss: 0.3361\n",
      "Epoch [45/50] - Iteration [200/226] - Discriminator Loss: -0.4273 - Generator Loss: 0.3356\n",
      "Epoch [46/50]\n",
      "Epoch [46/50] - Iteration [100/226] - Discriminator Loss: -0.4303 - Generator Loss: 0.3369\n",
      "Epoch [46/50] - Iteration [200/226] - Discriminator Loss: -0.4218 - Generator Loss: 0.3268\n",
      "Epoch [47/50]\n",
      "Epoch [47/50] - Iteration [100/226] - Discriminator Loss: -0.4286 - Generator Loss: 0.3147\n",
      "Epoch [47/50] - Iteration [200/226] - Discriminator Loss: -0.4287 - Generator Loss: 0.3361\n",
      "Epoch [48/50]\n",
      "Epoch [48/50] - Iteration [100/226] - Discriminator Loss: -0.4296 - Generator Loss: 0.3325\n",
      "Epoch [48/50] - Iteration [200/226] - Discriminator Loss: -0.4270 - Generator Loss: 0.3320\n",
      "Epoch [49/50]\n",
      "Epoch [49/50] - Iteration [100/226] - Discriminator Loss: -0.4202 - Generator Loss: 0.3318\n",
      "Epoch [49/50] - Iteration [200/226] - Discriminator Loss: -0.4032 - Generator Loss: 0.3417\n",
      "Epoch [50/50]\n",
      "Epoch [50/50] - Iteration [100/226] - Discriminator Loss: -0.4281 - Generator Loss: 0.3301\n",
      "Epoch [50/50] - Iteration [200/226] - Discriminator Loss: -0.4233 - Generator Loss: 0.3332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-23 01:17:14,644] Trial 3 finished with value: 4.571346700191498 and parameters: {'latent_dim': 78, 'learning_rate': 0.0003386473142959312, 'num_epochs': 50, 'batch_size': 32}. Best is trial 1 with value: -1.6689766645431519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Convergence Score: -1.6689766645431519\n",
      "Best Hyperparameters: {'latent_dim': 143, 'learning_rate': 0.0027601997252430545, 'num_epochs': 60, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 50, 200)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    image_channels = 3\n",
    "    image_size = 64\n",
    "    data_root = '/Users/isikgurhan/Desktop/data-jpg/alldata'\n",
    "\n",
    "    gan_estimator = GANEstimator(latent_dim, image_channels, image_size, learning_rate, data_root)\n",
    "\n",
    "    num_epochs = trial.suggest_categorical('num_epochs', [50, 60])  # Choose from 2 values\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64])  # Choose from 2 values\n",
    "    n_critic = 5\n",
    "    clip_value = 0.01\n",
    "    evaluation_interval = 100\n",
    "\n",
    "    initial_d_losses, initial_g_losses = gan_estimator.fit(\n",
    "        num_epochs=1, batch_size=batch_size, n_critic=n_critic, clip_value=clip_value, evaluation_interval=100\n",
    "    )\n",
    "\n",
    "    final_d_losses, final_g_losses = gan_estimator.fit(\n",
    "        num_epochs=num_epochs, batch_size=batch_size, n_critic=n_critic, clip_value=clip_value, evaluation_interval=100\n",
    "    )\n",
    "\n",
    "    d_convergence = sum(initial_d_losses) - sum(final_d_losses)\n",
    "    g_convergence = sum(initial_g_losses) - sum(final_g_losses)\n",
    "    convergence_score = d_convergence + g_convergence\n",
    "\n",
    "    return convergence_score\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "num_trials = 4\n",
    "for _ in range(num_trials):\n",
    "    study.optimize(objective, n_trials=1)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "\n",
    "print(f\"Best Convergence Score: {best_trial.value}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60]\n",
      "Epoch [1/60] - Iteration [100/113] - Discriminator Loss: -0.2792 - Generator Loss: 0.3210\n",
      "Epoch [2/60]\n",
      "Epoch [2/60] - Iteration [100/113] - Discriminator Loss: -0.2662 - Generator Loss: 0.3391\n",
      "Epoch [3/60]\n",
      "Epoch [3/60] - Iteration [100/113] - Discriminator Loss: -0.2637 - Generator Loss: 0.3134\n",
      "Epoch [4/60]\n",
      "Epoch [4/60] - Iteration [100/113] - Discriminator Loss: -0.2564 - Generator Loss: 0.3354\n",
      "Epoch [5/60]\n",
      "Epoch [5/60] - Iteration [100/113] - Discriminator Loss: -0.2711 - Generator Loss: 0.3360\n",
      "Epoch [6/60]\n",
      "Epoch [6/60] - Iteration [100/113] - Discriminator Loss: -0.2711 - Generator Loss: 0.3340\n",
      "Epoch [7/60]\n",
      "Epoch [7/60] - Iteration [100/113] - Discriminator Loss: -0.2619 - Generator Loss: 0.3230\n",
      "Epoch [8/60]\n",
      "Epoch [8/60] - Iteration [100/113] - Discriminator Loss: -0.2715 - Generator Loss: 0.3225\n",
      "Epoch [9/60]\n",
      "Epoch [9/60] - Iteration [100/113] - Discriminator Loss: -0.2571 - Generator Loss: 0.2454\n",
      "Epoch [10/60]\n",
      "Epoch [10/60] - Iteration [100/113] - Discriminator Loss: -0.2529 - Generator Loss: 0.3113\n",
      "Epoch [11/60]\n",
      "Epoch [11/60] - Iteration [100/113] - Discriminator Loss: -0.2443 - Generator Loss: 0.2759\n",
      "Epoch [12/60]\n",
      "Epoch [12/60] - Iteration [100/113] - Discriminator Loss: -0.2808 - Generator Loss: 0.3288\n",
      "Epoch [13/60]\n",
      "Epoch [13/60] - Iteration [100/113] - Discriminator Loss: -0.2713 - Generator Loss: 0.2896\n",
      "Epoch [14/60]\n",
      "Epoch [14/60] - Iteration [100/113] - Discriminator Loss: -0.2771 - Generator Loss: 0.3249\n",
      "Epoch [15/60]\n",
      "Epoch [15/60] - Iteration [100/113] - Discriminator Loss: -0.2800 - Generator Loss: 0.2774\n",
      "Epoch [16/60]\n",
      "Epoch [16/60] - Iteration [100/113] - Discriminator Loss: -0.2370 - Generator Loss: 0.2540\n",
      "Epoch [17/60]\n",
      "Epoch [17/60] - Iteration [100/113] - Discriminator Loss: -0.2691 - Generator Loss: 0.3195\n",
      "Epoch [18/60]\n",
      "Epoch [18/60] - Iteration [100/113] - Discriminator Loss: -0.2596 - Generator Loss: 0.2995\n",
      "Epoch [19/60]\n",
      "Epoch [19/60] - Iteration [100/113] - Discriminator Loss: -0.2721 - Generator Loss: 0.2923\n",
      "Epoch [20/60]\n",
      "Epoch [20/60] - Iteration [100/113] - Discriminator Loss: -0.2796 - Generator Loss: 0.2943\n",
      "Epoch [21/60]\n",
      "Epoch [21/60] - Iteration [100/113] - Discriminator Loss: -0.1772 - Generator Loss: 0.2260\n",
      "Epoch [22/60]\n",
      "Epoch [22/60] - Iteration [100/113] - Discriminator Loss: -0.2870 - Generator Loss: 0.2292\n",
      "Epoch [23/60]\n",
      "Epoch [23/60] - Iteration [100/113] - Discriminator Loss: -0.2842 - Generator Loss: 0.3099\n",
      "Epoch [24/60]\n",
      "Epoch [24/60] - Iteration [100/113] - Discriminator Loss: -0.2769 - Generator Loss: 0.3158\n",
      "Epoch [25/60]\n",
      "Epoch [25/60] - Iteration [100/113] - Discriminator Loss: -0.2752 - Generator Loss: 0.3111\n",
      "Epoch [26/60]\n",
      "Epoch [26/60] - Iteration [100/113] - Discriminator Loss: -0.2353 - Generator Loss: 0.2722\n",
      "Epoch [27/60]\n",
      "Epoch [27/60] - Iteration [100/113] - Discriminator Loss: -0.2735 - Generator Loss: 0.3006\n",
      "Epoch [28/60]\n",
      "Epoch [28/60] - Iteration [100/113] - Discriminator Loss: -0.2751 - Generator Loss: 0.3188\n",
      "Epoch [29/60]\n",
      "Epoch [29/60] - Iteration [100/113] - Discriminator Loss: -0.2886 - Generator Loss: 0.3016\n",
      "Epoch [30/60]\n",
      "Epoch [30/60] - Iteration [100/113] - Discriminator Loss: -0.2725 - Generator Loss: 0.3208\n",
      "Epoch [31/60]\n",
      "Epoch [31/60] - Iteration [100/113] - Discriminator Loss: -0.2754 - Generator Loss: 0.3208\n",
      "Epoch [32/60]\n",
      "Epoch [32/60] - Iteration [100/113] - Discriminator Loss: -0.2503 - Generator Loss: 0.2761\n",
      "Epoch [33/60]\n",
      "Epoch [33/60] - Iteration [100/113] - Discriminator Loss: -0.2770 - Generator Loss: 0.3065\n",
      "Epoch [34/60]\n",
      "Epoch [34/60] - Iteration [100/113] - Discriminator Loss: -0.2580 - Generator Loss: 0.3016\n",
      "Epoch [35/60]\n",
      "Epoch [35/60] - Iteration [100/113] - Discriminator Loss: -0.2647 - Generator Loss: 0.2655\n",
      "Epoch [36/60]\n",
      "Epoch [36/60] - Iteration [100/113] - Discriminator Loss: -0.2842 - Generator Loss: 0.3176\n",
      "Epoch [37/60]\n",
      "Epoch [37/60] - Iteration [100/113] - Discriminator Loss: -0.2740 - Generator Loss: 0.3148\n",
      "Epoch [38/60]\n",
      "Epoch [38/60] - Iteration [100/113] - Discriminator Loss: -0.2646 - Generator Loss: 0.2933\n",
      "Epoch [39/60]\n",
      "Epoch [39/60] - Iteration [100/113] - Discriminator Loss: -0.2685 - Generator Loss: 0.3101\n",
      "Epoch [40/60]\n",
      "Epoch [40/60] - Iteration [100/113] - Discriminator Loss: -0.2522 - Generator Loss: 0.3122\n",
      "Epoch [41/60]\n",
      "Epoch [41/60] - Iteration [100/113] - Discriminator Loss: -0.2622 - Generator Loss: 0.3218\n",
      "Epoch [42/60]\n",
      "Epoch [42/60] - Iteration [100/113] - Discriminator Loss: -0.2703 - Generator Loss: 0.2935\n",
      "Epoch [43/60]\n",
      "Epoch [43/60] - Iteration [100/113] - Discriminator Loss: -0.2569 - Generator Loss: 0.2867\n",
      "Epoch [44/60]\n",
      "Epoch [44/60] - Iteration [100/113] - Discriminator Loss: -0.2250 - Generator Loss: 0.2637\n",
      "Epoch [45/60]\n",
      "Epoch [45/60] - Iteration [100/113] - Discriminator Loss: -0.2759 - Generator Loss: 0.3202\n",
      "Epoch [46/60]\n",
      "Epoch [46/60] - Iteration [100/113] - Discriminator Loss: -0.2484 - Generator Loss: 0.2979\n",
      "Epoch [47/60]\n",
      "Epoch [47/60] - Iteration [100/113] - Discriminator Loss: -0.2581 - Generator Loss: 0.3042\n",
      "Epoch [48/60]\n",
      "Epoch [48/60] - Iteration [100/113] - Discriminator Loss: -0.2723 - Generator Loss: 0.3064\n",
      "Epoch [49/60]\n",
      "Epoch [49/60] - Iteration [100/113] - Discriminator Loss: -0.2801 - Generator Loss: 0.3016\n",
      "Epoch [50/60]\n",
      "Epoch [50/60] - Iteration [100/113] - Discriminator Loss: -0.2633 - Generator Loss: 0.3023\n",
      "Epoch [51/60]\n",
      "Epoch [51/60] - Iteration [100/113] - Discriminator Loss: -0.2747 - Generator Loss: 0.3068\n",
      "Epoch [52/60]\n",
      "Epoch [52/60] - Iteration [100/113] - Discriminator Loss: -0.2636 - Generator Loss: 0.2783\n",
      "Epoch [53/60]\n",
      "Epoch [53/60] - Iteration [100/113] - Discriminator Loss: -0.2354 - Generator Loss: 0.2823\n",
      "Epoch [54/60]\n",
      "Epoch [54/60] - Iteration [100/113] - Discriminator Loss: -0.2729 - Generator Loss: 0.3106\n",
      "Epoch [55/60]\n",
      "Epoch [55/60] - Iteration [100/113] - Discriminator Loss: -0.2761 - Generator Loss: 0.2974\n",
      "Epoch [56/60]\n",
      "Epoch [56/60] - Iteration [100/113] - Discriminator Loss: -0.2583 - Generator Loss: 0.2920\n",
      "Epoch [57/60]\n",
      "Epoch [57/60] - Iteration [100/113] - Discriminator Loss: -0.2449 - Generator Loss: 0.3018\n",
      "Epoch [58/60]\n",
      "Epoch [58/60] - Iteration [100/113] - Discriminator Loss: -0.2694 - Generator Loss: 0.3213\n",
      "Epoch [59/60]\n",
      "Epoch [59/60] - Iteration [100/113] - Discriminator Loss: -0.2520 - Generator Loss: 0.3006\n",
      "Epoch [60/60]\n",
      "Epoch [60/60] - Iteration [100/113] - Discriminator Loss: -0.2704 - Generator Loss: 0.2979\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_gan_estimator = GANEstimator(\n",
    "    latent_dim=best_params['latent_dim'],\n",
    "    image_channels=3,\n",
    "    image_size=64,\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    data_root='/Users/isikgurhan/Desktop/data-jpg/alldata'\n",
    ")\n",
    "\n",
    "best_d_losses, best_g_losses = best_gan_estimator.fit(\n",
    "    num_epochs=best_params['num_epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    n_critic=5,\n",
    "    clip_value=0.01,\n",
    "    evaluation_interval=100\n",
    ")\n",
    "\n",
    "best_gan_estimator.save_model('best_gan_weights.pth')\n",
    "\n",
    "# Plot losses\n",
    "best_gan_estimator.plot_losses(best_d_losses, best_g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
